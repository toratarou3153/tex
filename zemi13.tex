\documentclass[12pt]{jarticle}
\usepackage{a4wide}
\usepackage{amsmath}%数学記号
\usepackage{amssymb}%数学記号
\usepackage{epsfig}%図
\usepackage{latexsym}
\usepackage{supertabular}
\usepackage{graphicx}
\usepackage{color}
\usepackage{ascmac}
\usepackage{multicol}
\usepackage{ascmac}
\usepackage{systeme}
\usepackage{amsmath,cases}
\pagestyle{plain}

\newtheorem{theorem}{定理}[section]
\newtheorem{lemma}[theorem]{補題}
\newtheorem{proposition}[theorem]{命題}
\newtheorem{conjecture}[theorem]{予想}
\newtheorem{corollary}[theorem]{系}
\newtheorem{definition}[theorem]{定義}
\newtheorem{example}[theorem]{例}
\newtheorem{exercise}[theorem]{例題}
\newtheorem{problem}[theorem]{問}
\newtheorem{algorithm}[theorem]{アルゴリズム}
\newtheorem{remark}[theorem]{注意}

\def\qed{{\hfill$\square$}}
\def\proof{{\vspace{-0.3cm}f 証明: \,}}
\def\solution{{\vspace{-0.3cm}f 解: \,}}
\def\N{{\Bbb N}}
\def\Z{{\Bbb Z}}
\def\Q{{\Bbb Q}}
\def\R{{\Bbb R}}
\def\C{{\Bbb C}}
\def\F{{\Bbb F}}
\def\D{{\mathcal D}}
\def\mod{{\mathrm{mod\,\,}}}
\def\GL{{\mathrm{GL}}}
\def\GF{{\mathrm{GF}}}
\def\H{{\mathcal{H}}}

\setlength{\textwidth}{170mm}
\setlength{\textheight}{240mm}
\setlength{\oddsidemargin}{-5mm}
\setlength{\evensidemargin}{-5mm}
\setlength{\topmargin}{-10mm}
\setlength{\headheight}{0mm}
\setlength{\headsep}{10mm}

\title{項目反応理論}
\begin{document}
\maketitle
\section{特性値の推定}
項目反応理論では項目特性曲線などでその項目への正答率が求められる。しかし、項目が複数あるとき、特性値$\theta$を固定した場合、異なる項目への反応が互いに独立になる局所独立性が仮定されていた。これより、
\begin{eqnarray}
  \label{00}
  \displaystyle P(u_{i}|\theta) =\prod_{j = 1}^{n} p_{j}(\theta)
\end{eqnarray}
と表すことができる。実際のテストでこの仮定が満たされるためには、項目同士で反応が出ないように作るだけでなく、すべての問題がある特性値$\theta$を測定しているのが必須であるため、かなり強い仮定と言える。局所独立を仮定できるとすると、ある被験者の$p$個の反応を、
\begin{eqnarray}
  \label{01}
  \displaystyle u_{jk} =\left\{\begin{array}{l}1 \ 第j番目の項目点数がk点(正答)\\ 0 \ それ以外(誤答)\end{array}\right. k = 0,1,2,\cdots,m_{j} \ \ j = 1,2,\cdots,p
\end{eqnarray}
とすると、この特定の項目反応を得る確率は、
\begin{eqnarray}
  \label{02}
  \displaystyle P(u_{jk}|\theta) = \prod_{j = 1}^{p} \prod_{k = 0}^{m_j} P^{u_{jk}}_{jk}(\theta)
\end{eqnarray}
と書き表せる。これは、$2$値項目($\bigcirc$か$\times$など)の場合、
\begin{eqnarray}
  \label{03}
  \displaystyle P_{j}(\theta) = P_{j_1}(\theta),1 - P_j(\theta) = P_{j_0}(\theta),u_j = u_{j_1},1 - u_j = u_{j_0}
\end{eqnarray}
として、
\begin{align}
  \label{04}
  \displaystyle P(u_{i}|\theta) &= \prod_{j = 1}^{p} (1 - P_j(\theta))^{1 - u_j}P_j(\theta)^{u_j}\\
  &=\prod_{j = 1}^{p} P_{j_0}(\theta)^{u_{j_0}}P_{j_1}(\theta)^{u_{j_1}}
\end{align}
となる。したがって、これをパラメータ$\theta$の尤度$L$と見なせば、これを最大化する$\theta$の値が被験者の特性値となる。特に$2$母数ロジスティックモデルの場合、対数尤度関数は以下のようになる。
\begin{align*}
  \label{05}
  \displaystyle \ln L &= \ln \left(\prod_{j = 1}^{p} (1 - P_j(\theta))^{1 - u_j}P_j(\theta)^{u_j}\right)\\
  &= \sum_{j = 1}^{p} \left(u_j\ln P_j(\theta) + (1 - u_j)\ln(1 - P_j(\theta)) \right) \\
  &= \sum_{j = 1}^{p}  u_j(\ln P_J(\theta)- \ln (1 - P_j(\theta))) + \ln (1 - P_j(\theta)) \\
  &= \sum_{j = 1}^{p} u_j \ln \frac{P_j(\theta)}{1 - P_j(\theta)} + \ln(1-P_j(\theta)) \\
  &= \sum_{j = 1}^{p} u_j  Da_j(\theta - b_j) + \ln(1-P_j(\theta)) \\
  &= D(\sum_{j = 1}^{p}a_ju_j)\theta  + \sum_{j = 1}^{p} \ln (1 - P_j(\theta)) - D(\sum_{j = 1}^{p} a_jb_ju_j) \tag{7}
\end{align*}
この形から、対数尤度関数の極致は、識別力で重みをつけた重み付き正答数得点、
\begin{align}
  \label{06}
  \displaystyle x^{\ast} &= \sum_{j = 1}^{p} a_j b_j u_j \tag{8}
\end{align}
のみに依存していることがわかる。つまり、$x^{\ast}$が同じ値の被験者の$\theta$の推定量は同じといえる。これを$\theta$の推定に際する十分統計量と呼ぶ。ただし、尤度関数自体は、項目反応パタンに依存し、例えば$1$母数ロジスティックモデルの場合は、難易度の高い$5$項目のみに正解した人の尤度は、難易度の低い$5$項目のみに正解した人の尤度より低くなる。(難易度が高い問題$5$項目に全問正解するほうが難しいから)
また、$\theta$の事前分布を$h(\theta)$としベイズ推定を用いれば$\theta$の事後分布は、項目反応が得あられる確率に事前分布をかけたもの
\begin{align*}
  \label{07}
  \displaystyle h(\theta|\boldsymbol{u})&=\prod_{j = 1}^{p} \prod_{k = 0}^{m_j} {P_{jk}}^{u_{jk}}(\theta)\times h(\theta)\\
  あるいは\\
  h(\theta|\boldsymbol{u}) &= \prod_{j = 1}^{p} (1 - P_j(\theta))^{1 - u_j}P_j(\theta)^{u_j} \times h(\theta) \tag{9}
\end{align*}
となり、その事後平均が$\theta$の推定値、その事後標準偏差が推定値の精度の悪さを表すことになる。母集団が$1$つしかない場合通常は、事前分布に標準正規分布を仮定するため、$h(\theta) = h(\theta|\mu)$とすることが多い。
\end{document}
